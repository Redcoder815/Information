{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Input-to-hidden\n",
    "        self.W_z = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
    "        self.W_r = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
    "        self.W_h = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
    "\n",
    "        # Hidden-to-hidden\n",
    "        self.U_z = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
    "        self.U_r = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
    "        self.U_h = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
    "\n",
    "        # Biases\n",
    "        self.b_z = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_r = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        # x_t: (batch, input_size)\n",
    "        # h_prev: (batch, hidden_size)\n",
    "\n",
    "        z_t = torch.sigmoid(\n",
    "            x_t @ self.W_z.T + h_prev @ self.U_z.T + self.b_z\n",
    "        )\n",
    "        r_t = torch.sigmoid(\n",
    "            x_t @ self.W_r.T + h_prev @ self.U_r.T + self.b_r\n",
    "        )\n",
    "\n",
    "        h_tilde = torch.tanh(\n",
    "            x_t @ self.W_h.T + (r_t * h_prev) @ self.U_h.T + self.b_h\n",
    "        )\n",
    "\n",
    "        h_t = (1 - z_t) * h_prev + z_t * h_tilde\n",
    "        return h_t\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = GRUCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        if h0 is None:\n",
    "            h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else:\n",
    "            h_t = h0\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]          # (batch, input_size)\n",
    "            h_t = self.cell(x_t, h_t) # (batch, hidden_size)\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "        # Concatenate over time\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
    "        return outputs, h_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
